\section{Semantic Analysis}

Semantic analysis is the process of checking the program for semantic errors,
such as type errors, and ensuring that the program is well-formed. This is done
after the parsing stage, where the abstract syntax tree has been constructed.
The semantic analysis stage is where the compiler ensures that the program is
semantically correct, and can be translated to the target language. This is done
by traversing the abstract syntax tree, and checking that the program adheres to
the rules of the language.

\subsection{Visitor Trait}

The \code{Visitor} trait has been mentioned in the previous section, but it is
now crucial to define it and describe it properly.

\begin{mainbox}{}
    \lstset{xleftmargin=0.2\textwidth, aboveskip=0pt, belowskip=0pt}
    \begin{lstlisting}[language=Rust]
pub trait Visitor<T> {
    fn visit(&mut self, node: &AstNode) -> T;
}
\end{lstlisting}
\end{mainbox}

The \code{Visitor} trait is a generic trait that takes a type parameter \code{T}
and defines a single method, \code{visit}, which takes a mutable reference to
the struct that implements the trait, and a reference to an AST node. The method
returns a value of type \code{T}.

The generic type parameter \code{T} is central to the way we will be using, or
rather, re-using the visitor trait in the code generation stage. It will allow
us to control the return type of the \code{visit} method, and thus, the type of
the value that is returned when visiting a node in the abstract syntax tree. In
other words, we can access, or evaluate, information about an AST node,
depending on the struct that implements the \code{Visitor} trait.

I have implemented the \code{Visitor} trait on a number of structs (here on referred to as Visitors), and these are:

\begin{itemize}
    \item \code{Formatter}: A visitor that parses, and then \textit{un-parses} the AST,
          rewriting the source in an (un-configurable) opinionated style. Similar to running \code{cargo fmt}.
    \item \code{TreePrinter}: A visitor mainly used for debugging the parsing
          stage, which prints the AST in a vertical tree-like structure.
    \item \code{SemanticAnalyser}: The visitor that performs the semantic analysis
          on the AST, checking for type errors, and ensuring the program is well-formed.
    \item \code{PArIRWriter}: The visitor that generates the PArIR code from the AST.
\end{itemize}

In this report I will describe the latter two, as they are part of the
requirements for the project.

\newpage

\subsection{Type/Scope Checking}

The \code{SemanticAnalyser}, other than being a visitor, also contains a number
of structs inside of it, which are used to keep track of the current scope, and
the types of variables that are in scope.

\begin{mainbox}{}
    \lstset{xleftmargin=3.5cm, aboveskip=0pt, belowskip=0pt}
    \begin{lstlisting}[language=Rust]
struct SemanticAnalyser {
    symbol_table: Vec<SymbolTable>,
    inside_function: bool,
    scope_peek_limit: usize,
    results: SemanticResult,
}
\end{lstlisting}
\end{mainbox}

The \code{SemanticAnalyser} struct contains a vector of \code{SymbolTable}s,
which functions as a stack. Each \code{SymbolTable} contains a mapping of
variable names (lexeme) to their types (\code{SymbolType}). My implementation of
\code{SymbolType} also further differentiates between identifiers that belong to
a function, array, or primitive type variable definitions. In the case of
functions, I stored the entire signature, including the return type, and the
types of the parameters.

An implementation detail of the \code{SymbolTable} is that it is a sorted
\code{LinkedList}, which allows for faster lookups. We ensure the list is
ordered at the moment of insertion, where we lexicographically compare the
lexemes of the identifiers we are storing in the symbol table.


Additionally, the \code{SemanticAnalyser} struct keeps track of whether the
visitor is currently is inside a function, through the \code{inside\_function}
flag. Different behaviour is expected from the visitor when inside a function,
for example, when checking for the existence of an identifier, we are only
allowed to look for it in the current scope, and not in the global scope.

The \code{scope\_peek\_limit} field is used to limit the number of scopes that
the visitor can look up when checking for the existence of an identifier. Used
in conjunction with the \code{inside\_function} flag, it allows the visitor to
only look up to a certain number of scopes when inside a function, and all the
way up to the global scope when outside of a function.

Finally, we have the \code{results} field, of the type \code{SemanticResult}.
This is simply a struct that contains two lists of possible errors that can be
emitted during the semantic analysis stage. We categorize these errors as
\code{Warnings}, i.e. possible involuntary mistakes performed by the user that
do not necessarily disallow the compilation of the program, and \code{Errors},
i.e. mistakes that must be fixed before the program can be compiled.

\vfill

\begin{warningbox}{Variable Shadowing}
    This implementation of the \code{ParL} compiler allows for \textit{variable
        shadowing}, in a similar fashion to Rust \cite{rustlangScopeShadowing}.  This means that a variable
    can be re-declared in an inner scope, and the latter will \textit{take over}
    the former for the life-time of the inner scope. Variable shadowing will
    produce a warning, as it can lead to confusion, but variable re-declaration
    in the same scope will always produce an error.
\end{warningbox}

\vfill
\newpage

Now that we know what tools the semantic analyser has at its disposal, we still
have one more thing to discuss. How do we find out the types of arbitrary
expressions, possibly with a mixture of literals, variables, function calls, and
operations applied to them? To answer this question we must define the type
inference of operations between types in the language. These are the types available.

\begin{multicols}{3}
    \begin{center}
        \code{Int}
    \end{center}

    \begin{center}
        \code{Float}
    \end{center}

    \begin{center}
        \code{Colour}
    \end{center}

    \begin{center}
        \code{Bool}
    \end{center}

    \begin{center}
        \code{Array<T>}
    \end{center}

    \begin{center}
        Void
    \end{center}
\end{multicols}

\begin{table}[H]
    \centering
    \begin{subtable}{.5\textwidth}
        \begin{tabular}{c|cccc}
            \begin{tabular}[c]{@{}c@{}} \code{+ -}\\ \code{* /}\end{tabular} & Int   & Float & Colour & Boolean \\ \hline
            Int                                                              & Int   & Float & N/A    & N/A     \\
            Float                                                            & Float & Float & N/A    & N/A     \\
            Colour                                                           & N/A   & N/A   & Colour & N/A     \\
            Bool                                                             & N/A   & N/A   & N/A    & N/A
        \end{tabular}
        \caption{Addition, subtraction, multiplication, and division operations between types.}
    \end{subtable}%
    \begin{subtable}{.5\textwidth}
        \centering
        \begin{tabular}{c|cccc}
            \begin{tabular}[c]{@{}c@{}} \code{== != <}\\ \code{> <= >=}\end{tabular} & Int  & Float & Colour & Boolean \\ \hline
            Int                                                                      & Bool & Bool  & N/A    & N/A     \\
            Float                                                                    & Bool & Bool  & N/A    & N/A     \\
            Colour                                                                   & N/A  & N/A   & Bool   & N/A     \\
            Bool                                                                     & N/A  & N/A   & N/A    & Bool
        \end{tabular}
        \caption{Comparison operations between types.}
    \end{subtable}
\end{table}
\label{tab:type-inference1}


\begin{table}[H]
    \centering
    \begin{subtable}{.5\textwidth}
        \centering
        \begin{tabular}{c|cccc}
            \code{\%} & Int & Float & Colour & Boolean \\ \hline
            Int       & Int & N/A   & N/A    & N/A     \\
            Float     & N/A & N/A   & N/A    & N/A     \\
            Colour    & N/A & N/A   & N/A    & N/A     \\
            Bool      & N/A & N/A   & N/A    & N/A
        \end{tabular}
        \caption{Modulo operation between types.}
    \end{subtable}%
    \begin{subtable}{.5\textwidth}
        \centering
        \begin{tabular}{c|cccc}
            \code{and or} & Int & Float & Colour & Boolean \\ \hline
            Int           & N/A & N/A   & N/A    & N/A     \\
            Float         & N/A & N/A   & N/A    & N/A     \\
            Colour        & N/A & N/A   & N/A    & N/A     \\
            Bool          & N/A & N/A   & N/A    & Bool
        \end{tabular}
        \caption{Logical operations between types.}
    \end{subtable}
\end{table}
\label{tab:type-inference2}

Every time we encounter an operation between two types, we must thus check the
tables above to see if the operation is valid. If it is, we can infer the type
of the operation, and continue checking the rest of the expression. If it is
not, the semantic analyser must emit an error, and stop the compilation process.

\begin{warningbox}{Type Inference}
    This type inference was only possible due to the flexibility between the
    operations performed in the VM itself. Given the VM is implemented in
    JavaScript, this flexibility is warranted, as JavaScript is a dynamically
    typed language. Had it been done on actual hardware, the type inference would
    have been much more rigid, and the checking must have been more strict,
    possibly with more intricate conversions to achieve the desired result.
\end{warningbox}

Behind the scenes, the compiler actually assigns a type to unsupported
operations, namely the \code{Unknown} type, which by default is incompatible
with any operation.

This is the general idea behind evaluating types of expressions in the
\code{SemanticAnalyser} visitor. How do we determine however the true return
type of a function declaration, or a \code{Block}? Well, we just traverse the
\code{AST} until we hit a \code{Return} statement, and then we check the type of
the expression that is being returned. Since we are not allowed to have
functions that do not return anything, any \code{Block} is at first assigned the
\code{Void} type, and if it remains so until the end of the block, an error is
emitted.

With all the type information of the symbols present in the program acquired,
the semantic analyser will check this against the type provided by the user in
the function signature, or variable declaration, and will emit a type mismatch
error, stating what the type it expected is (the one the user defined) and what
it found, the type of the returned expression. In the case of arrays, lengths
must also match.

\newpage

Additionally, in the case of \code{For} loops, there is one additinoal thing to
pay attention to. Even though the body of for loop is a block in its own right,
we must actually start the scope of the for loop before the body, but then, we
cannot visit the body with the normal rules. In fact, a new function called \code{visit\_unscoped\_block} was created to override the normal behaviour of visiting a block, and instead, visit it without creating a new scope. This is crucial for the for loop, as the variables declared in the for loop must be accessible in the body of the loop (and because we can't shadow the iterator variable).

Lastly, type-casting is also supported in the language, and is done by using the
\code{as} keyword. The type-casting operation is only allowed between specific
types, otherwise an error is emitted.

\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}

\begin{table}[H]
    \centering
    \begin{tabular}{cc|cccc}
               & to & Int        & Float      & Colour     & Boolean    \\
        from   &    &            &            &            &            \\ \hline
        Int    &    & \checkmark & \checkmark & \checkmark & $\times$   \\
        Float  &    & $\times$   & \checkmark & $\times$   & $\times$   \\
        Colour &    & \checkmark & \checkmark & \checkmark & $\times$   \\
        Bool   &    & \checkmark & \checkmark & $\times$   & \checkmark
    \end{tabular}
    \caption{Type-casting operations between types.}
    \label{tab:type-casting}
\end{table}

\begin{warningbox}{Limitation}
    The type-casting operation is only supported
    between the types listed in the table above. However, this may cause some
    overflows, which are not check for in the compiler. A clear example is taking
    the \code{Colour} \code{\#ffffff}, casting it to an \code{Int}, adding one, and casting it back to a \code{Colour}. Drawing this on the display will result in a black pixel, as the \code{Int} overflowed.\\

    A further improvement could be an overflow check implemented on types with arbitrary values that have fixed ranges, such as \code{Int} and \code{Floats}.
    In fact, whilst converting array indices from a lexeme to a Rust \code{usize}, we assume that the lexeme represents a valid \code{usize}. If it is too big, the compiler will crash due to an \code{unwrap()}.
\end{warningbox}

To summarize, the following are the rules we shall impose on the language:

\begin{itemize}
    \item Atomic variables, functions and arrays must be declared before they are used.
    \item Atomic variables, functions and arrays cannot be re-declared in the same scope.
    \item Atomic variable and array declaratinos can be shadowed in inner scopes.
    \item When declaring arrays, the number of elements must match the length of
          the array, so overallocation is not allowed.
    \item Functions cannot be called with the wrong number of arguments.
    \item Function parameters must match the types in the function signature.
    \item Functions must return a value.
    \item Functions must return the correct type.
    \item Operations between types must be valid.
    \item The type of the expression in a return statement must match the return type of the function.
\end{itemize}
