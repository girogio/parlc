\newcommand{\bnfTerm}[1]{\langle\, \text{#1}\, \rangle}

\section{Parsing the Token Stream}

Parsing the token stream generated by the lexer is where the Rust language
really shines. It allows to define an enum, called \code{AstNode}, which
represents the different types of nodes that can be found in the abstract syntax
tree of a \code{ParL} program. Additionally, we can mix and match different
types of variants, such as ones with no data (similar to unit-like structs, like
\code{struct Foo;}), ones with unnamed data (similar to tuple structs, like
\code{struct Foo(i32, i32);}), and ones with named data (similar to regular
structs, like \code{struct Foo \{ x: i32, y: i32 \};}).

This gives us much more flexibility when defining the AST, in contrast to C or
C++, where enums are basically just integers. Furthermore, I had to create a
type alias from \code{Box<AstNode>} to \code{AstNodePtr}. This is because
certain \code{AstNode} variants, have another \code{AstNode} as a child. The
Rust compiler complains about the enum having infinite size, as it is can't be
calculated at compile time. This is understandable, as for example, if the
\code{AstNode::Expression} variant contained another \code{AstNode} as its
member, the compiler would try to recursively visit this member to check its
size, which could also be an expression, visiting the same member again, and so
on. With a \code{Box}, the size of the enum is known at compile time, as it is
just a pointer to the heap, and the compiler is happy. Lists of \code{AstNode}s,
like parameter lists, do not need this, as a Rust \code{Vec} is already
allocated on the heap.

The actual parser is implemented as a struct called \code{Parser}, which must be
initialized with the list of tokens generated by the lexer. The parser privately
defines all the different parsing functions. The only public function is
\code{parse}, which is called to start the parsing process. The parser uses a
recursive descent parsing algorithm, together with the Rust pattern matching
feature, which is used to differentiate between the different variants of the
\code{AstNode} enum.

Due to this, the Visitor design pattern is slightly different in Rust. With
pattern matching, we avoid having every variant of the \code{AstNode} enum
requiring it's own \code{accept} method. Instead we define each case in the
\code{match} clause in the \code{visit} method for a given struct implementing
the \code{Visitor} trait. Pattern matching is thoroughly used to ensure
correctness and to avoid unnecessary code duplication.

A number of utility functions, such as \code{consume\_if(kind:\,Tokenind)}, and
\code{assert\_token\_is\_any}\\\code{(kind:\ Vec<TokenKind>)}, are used to
simplify the parsing process. The former consumes a token if it matches the
given \code{TokenKind}, and returns an error otherwise. This is useful as it in
allows the user to quickly identify syntax errors in the input program, with the
parser suggesting what it was expecting, and announcing what it found instead.
The latter function, asserts that the current token is any of the given
\code{TokenKind}s, and returns an error if it is not. This is useful when the
parser is expecting one of a number of different tokens, such as when declaring
a variable, we expect either an \code{int}, \code{float}, \code{colour} or
\code{bool} token kind after the semicolon. The error outputted will be more
informative, as it will list all the possible token kinds that were expected.



The full list of the \code{AstNode} enum variants can be found in Appendix
\ref{sec:parser-ast-node-enum}.

\subsection{Syntax Modifications}

It is worth noting that the original grammar for the parser was not perfect. The
precedence of the operators was not correctly defined, leading to incorrect
parsing of expressions.  For example, the
expression $$\code{a < b and c >= d}$$ was being parsed as $$\code{a < (b and c)
        >= d}$$ which is expected from a programming language that treats the
\code{`and'} and \code{`or'} keywords as its bitwise operators.  After
observing the behavior of these operators in the VM (they are indeed logical
operators), the correct parsing should be $$\code{(a < b) and (c >= d)}$$ The
\code{`and'} and \code{`or'} operators were being parsed with a higher
precedence than the comparison operators. Whilst researching alternative
expression grammars, I stumbled upon the Lox language \cite{nystrom2021crafting}, and
decided to take inspiration from it use its production rules for expressions.

The new production rules for expressions are as follows:
\begin{align*}
    \bnfTerm{Expression} & ::= \bnfTerm{Equality} \ \{ \ ( \ \text{`and'} \ |\  \text{`or'} \ )\ \bnfTerm{Equality} \ \}                                 \\
    \bnfTerm{Equality}   & ::= \bnfTerm{Comparison} \ \{ \ ( \ \text{`!='} \ |\  \text{`=='} \ )\  \bnfTerm{Comparison} \ \}                             \\
    \bnfTerm{Comparison} & ::= \bnfTerm{Term} \ \{ \ ( \ \text{`<='} \ |\  \text{`<'} \ |\  \text{`>='} \ |\  \text{`>'} \ )\  \bnfTerm{Term}  \ \}      \\
    \bnfTerm{Term}       & ::= \bnfTerm{Factor} \ \{ \ ( \ \text{`+'} \ |\  \text{`-'} \ )\ \bnfTerm{Factor} \ \}                                        \\
    \bnfTerm{Factor}     & ::= \bnfTerm{Unary} \ \{ \ ( \ \text{`*'} \ |\  \text{`/'} \ |\ \text{`\%'} \ )\ \bnfTerm{Unary} \ \}                         \\
    \bnfTerm{Unary}      & ::=  ( \ \text{`!'} \ |\  \text{`-'} \ ) \ \bnfTerm{Unary} \ |\ \bnfTerm{Primary}                                             \\
    \bnfTerm{Primary}    & ::= \bnfTerm{Literal} \ \ |\
    \bnfTerm{Identifier} \ |\ \bnfTerm{FunctionCall} \ |\ \bnfTerm{SubExpr}
    \                                                                                                                                                    \\
                         & \quad | \ \bnfTerm{Unary} \ | \ \bnfTerm{PadRandI} \ | \ \bnfTerm{PadWidth} \ | \ \bnfTerm{PadHeight} \ | \ \bnfTerm{PadRead}
\end{align*}

One may also notice the addition of the $\code{\%}$ operator, known as the
modulo.  Although this wasn't specified in the original grammar, it is present
as an instruction in the VM, so I decided to include it. In the context of
drawing pixels, it's useful for creating a wrap-around effect in loops.

